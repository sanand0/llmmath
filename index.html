<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLM Mental Math</title>
  <link
    rel="icon"
    type="image/svg+xml"
    href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAzMiAzMiI+PGNpcmNsZSBjeD0iMTYiIGN5PSIxNiIgcj0iMTUiIGZpbGw9IiMyNTYzZWIiLz48cGF0aCBmaWxsPSIjZmZmIiBkPSJtMTYgNyAyIDcgNyAyLTcgMi0yIDctMi03LTctMiA3LTJaIi8+PC9zdmc+" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    .narrative {
      max-width: 40rem;
    }

    .popover-body {
      white-space: pre-wrap;
      font-family: var(--bs-font-monospace);
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</head>

<body>
  <div class="container py-5">
    <h1 class="display-1 my-4 text-center">LLM Mental Math</h1>
    <h2 class="display-6 text-center">How well can LLMs multiply?</h2>
    <div class="fs-5 my-5 p-3 mx-auto narrative bg-light rounded-3">
      <p>I asked 50 LLMs to multiple 2 numbers:</p>
      <ol>
        <li>12 x 12</li>
        <li>123 x 456</li>
        <li>1,234 x 5,678</li>
        <li>12,345 x 6,789</li>
        <li>123,456 x 789,012</li>
        <li>1,234,567 x 8,901,234</li>
        <li>987,654,321 x 123,456,789</li>
      </ol>
      <p>LLMs aren&#39;t good tools for math and this is just an informal check. But the results are interesting:</p>
    </div>

    <table class="table table-hover table-bordered">
      <thead class="table-dark">
        <tr id="headerRow"></tr>
      </thead>
      <tbody id="body"></tbody>
      <tfoot id="foot"></tfoot>
    </table>

    <div class="fs-5 my-5 p-3 mx-auto narrative bg-light rounded-3">
      <ol>
        <li><strong>OpenAI&#39;s reasoning models cracked it</strong>, scoring 6/7, stumbling only on the 9-digit multiplication.</li>
        <li><strong>OpenAI&#39;s other models and DeepSeek V3 were next</strong>, getting the first 5/7 right. Notably: GPT 4.1 Mini beat GPT 4.1. DeepSeek V3 beat DeepSeek R1.</li>
        <li>16 models, including the latest Gemini, Anthropic, and Llama models get 4/7 right.</li>
        <li>The Amazon models, older Llama, Anthropic, Google, OpenAI models get 3 or less right.</li>
      </ol>
      <p><strong>Models use human-like mental math tricks</strong>.</p>
      <p>For example, O3-Mini-High calculated 1234567 × 8901234 using a recursive strategy.</p>
      <p>DeepSeek V3 double-checks results and hallucinates a &quot;reliable computational tool&quot;.</p>
      <p>O3 Mini reframes 8901234 as (9000000 − 98766) to simplify the calculation.</p>
      <p>For more details, see the repo at <a href="https://github.com/sanand0/llmmath">github.com/sanand0/llmmath</a>.</p>
    </div>

  </div>

  <script type="module">
    const { config, results } = await(await fetch('multiplication.json')).json();
    const tests = config.tests.map(t => t.description.replace(/,/g, '').replace(/\s*x\s*/g, 'x'));;
    const entries = results.results;
    const models = [...new Set(entries.map(r => r.provider.id || r.provider))];
    const stats = models.map(m => {
      const res = { m, pass: 0, fail: 0, error: 0, blank: 0, totalAttempts: 0 };
      tests.forEach((d, i) => {
        const r = entries.filter(r => (r.provider.id || r.provider) === m && `${r.vars.a}x${r.vars.b}` === d);
        const attempts = r.length;
        const correct = r.filter(r => r.success).length;
        const errors = r.filter(r => r.response?.error).length;
        const blanks = r.filter(r => !(r.response?.output || '').trim() && !r.response?.error).length;
        const fails = attempts - correct - errors - blanks;
        res[d] = {attempts,correct,blanks,errors,fails,accuracy: attempts > 0 ? Math.round((correct / attempts) * 100) : 0
        };
        res.totalAttempts += attempts;
        res.pass += correct;
        res.blank += blanks;
        res.error += errors;
        res.fail += fails;

      });

      res.overallAccuracy = res.totalAttempts > 0 ? Math.round(res.pass / res.totalAttempts * 100) : 0;
      return res;
    });

    // sort by overall accuracy, name
    stats.sort((a, b) => b.overallAccuracy - a.overallAccuracy || a.m.localeCompare(b.m));

    // header
    document.getElementById('headerRow').innerHTML =
      ['m', '%Win', ...tests].map(h => `<th>${h}</th>`).join('');

    // body
    const b = document.getElementById('body');
    stats.forEach(s => {
      const cells = tests.map(d => {
        const r = s[d];
        const text = `${r.correct}/${r.attempts} (${r.accuracy}%)`;
        const cls = r.accuracy === 100 ? 'table-success' : r.accuracy >= 50 ? 'table-warning' : 'table-danger';
        return `<td class="${cls}" data-bs-toggle="popover" data-bs-placement="top" data-bs-content="${text}">${text}</td>`;
      }).join('');

      b.insertAdjacentHTML('beforeend',
        `<tr>
          <th>${s.m}</th>
          <td>${s.pass}/${s.totalAttempts} (${s.overallAccuracy}%)</td>
          ${cells}
        </tr>`);
    });

    // Initialize popovers
    bootstrap.Popover.getOrCreateInstance(document.body, { selector: '[data-bs-toggle="popover"]', trigger: 'hover' });

    // footer averages
    const f = document.getElementById('foot');
    const avg = tests.map(d => {
      const pass = stats.reduce((sum, s) => sum + s[d].correct, 0);
      const totalAttempts = stats.reduce((sum, s) => sum + s[d].attempts, 0);
      return totalAttempts > 0 ? Math.round(pass / totalAttempts * 100) : 0;
    });
    f.innerHTML = `<tr class="table-secondary"><th>Average</th><th></th>${avg.map(a => `<th>${a}%</th>`).join('')}</tr>`;

  </script>
</body>

</html>
