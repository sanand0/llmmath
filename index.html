<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLM Mental Math</title>
  <link
    rel="icon"
    type="image/svg+xml"
    href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAzMiAzMiI+PGNpcmNsZSBjeD0iMTYiIGN5PSIxNiIgcj0iMTUiIGZpbGw9IiMyNTYzZWIiLz48cGF0aCBmaWxsPSIjZmZmIiBkPSJtMTYgNyAyIDcgNyAyLTcgMi0yIDctMi03LTctMiA3LTJaIi8+PC9zdmc+" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    .narrative {
      max-width: 40rem;
    }

    .popover-body {
      white-space: pre-wrap;
      font-family: var(--bs-font-monospace);
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
</head>

<body>
  <div class="container py-5">
    <h1 class="display-1 my-4 text-center">LLM Mental Math</h1>
    <h2 class="display-6 text-center">How well can LLMs multiply?</h2>
    <div class="fs-5 my-5 p-3 mx-auto narrative bg-light rounded-3">
      <p>I asked 50 LLMs to multiple 2 numbers:</p>
      <ol>
        <li>12 x 12</li>
        <li>123 x 456</li>
        <li>1,234 x 5,678</li>
        <li>12,345 x 6,789</li>
        <li>123,456 x 789,012</li>
        <li>1,234,567 x 8,901,234</li>
        <li>987,654,321 x 123,456,789</li>
      </ol>
      <p>LLMs aren&#39;t good tools for math and this is just an informal check. But the results are interesting:</p>
    </div>

    <table class="table table-hover table-bordered">
      <thead class="table-dark">
        <tr id="headerRow"></tr>
      </thead>
      <tbody id="body"></tbody>
      <tfoot id="foot"></tfoot>
    </table>

    <div class="fs-5 my-5 p-3 mx-auto narrative bg-light rounded-3">
      <ol>
        <li><strong>OpenAI&#39;s reasoning models cracked it</strong>, scoring 6/7, stumbling only on the 9-digit multiplication.</li>
        <li><strong>OpenAI&#39;s other models and DeepSeek V3 were next</strong>, getting the first 5/7 right. Notably: GPT 4.1 Mini beat GPT 4.1. DeepSeek V3 beat DeepSeek R1.</li>
        <li>16 models, including the latest Gemini, Anthropic, and Llama models get 4/7 right.</li>
        <li>The Amazon models, older Llama, Anthropic, Google, OpenAI models get 3 or less right.</li>
      </ol>
      <p><strong>Models use human-like mental math tricks</strong>.</p>
      <p>For example, O3-Mini-High calculated 1234567 × 8901234 using a recursive strategy.</p>
      <p>DeepSeek V3 double-checks results and hallucinates a &quot;reliable computational tool&quot;.</p>
      <p>O3 Mini reframes 8901234 as (9000000 − 98766) to simplify the calculation.</p>
      <p>For more details, see the repo at <a href="https://github.com/sanand0/llmmath">github.com/sanand0/llmmath</a>.</p>
    </div>

  </div>

  <script type="module">
    const { config, results } = await(await fetch('multiplication.json')).json();
    const tests = config.tests.map(t => t.description);
    const entries = results.results;
    const models = [...new Set(entries.map(r => r.provider.id || r.provider))];
    const stats = models.map(m => {
      const res = { model: m, pass: 0, fail: 0, error: 0, blank: 0 };
      tests.forEach((d, i) => {
        const r = entries.find(r => (r.provider.id || r.provider) === m && r.testIdx === i);
        const o = r.response;
        if (o?.error) res.error++;
        else if (!(o?.output || '').trim()) res.blank++;
        else if (r.success) res.pass++;
        else res.fail++;
      });
      const den = res.pass + res.fail;
      res.win = den ? Math.round(res.pass / den * 100) : 0;
      return res;
    });

    // sort by win desc, fail desc, name
    stats.sort((a, b) => b.win - a.win || b.fail - a.fail || a.model.localeCompare(b.model));

    // header
    document.getElementById('headerRow').innerHTML =
      ['Model', '%Win', ...tests].map(h => `<th>${h}</th>`).join('');

    // body
    const b = document.getElementById('body');
    stats.forEach(s => {
      const cells = tests.map((d, i) => {
        const r = entries.find(r => (r.provider.id || r.provider) === s.model && r.testIdx === i);
        const o = r.response;
        const st = o?.error ? 'ERROR' : !(o?.output || '').trim() ? 'BLANK' : (r.success ? 'PASS' : 'FAIL');
        const cls = st === 'PASS' ? 'table-success' : st === 'FAIL' ? 'table-danger' : 'table-warning';
        return `<td class="${cls}" data-bs-toggle="popover" data-bs-placement="top" data-bs-content="${o.error ?? o.output}">${st}</td>`;
      }).join('');
      b.insertAdjacentHTML('beforeend', `<tr><th>${s.model}</th><td>${s.win}%</td>${cells}</tr>`);
    });

    // Initialize popovers
    bootstrap.Popover.getOrCreateInstance(document.body, { selector: '[data-bs-toggle="popover"]', trigger: 'hover' });

    // footer averages
    const f = document.getElementById('foot');
    const avg = tests.map((d, i) =>
      Math.round(stats.filter(s => {
        const r = entries.find(r => (r.provider.id || r.provider) === s.model && r.testIdx === i);
        return r.success;
      }).length / models.length * 100)
    );
    f.innerHTML = `<tr class="table-secondary"><th>Average</th><th></th>` +
      avg.map(a => `<th>${a}%</th>`).join('') + `</tr>`;
  </script>
</body>

</html>
